# -*- coding: utf-8 -*-
"""Wamito_Wholesale_Drinks_Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vEXlj-6vVQuMm-ekzVuDsQQidOqjrS5C
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from mlxtend.frequent_patterns import apriori, association_rules
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# Set Good Visualizations
plt.style.use('seaborn-v0_8')
sns.set_palette("viridis")

# Create output directory for saving figures and results
import os
if not os.path.exists('output'):
    os.makedirs('output')

# Load Data
df = pd.read_csv('Wamito_Wholesale_Drinks_Data.csv')

# Data Cleaning
print("\n======== Data Cleaning & Preprocessing ========\n")

# Check on Missing Values
print("\nMissing Values")
print(df.isnull().sum())

# Validate TotalRevenue calculation (UnitPrice * QuantitySold)
df['CalculatedRevenue'] = df['UnitPrice'] * df['QuantitySold']
revenue_mismatch = df[abs(df['TotalRevenue'] - df['CalculatedRevenue']) > 0.01]
if not revenue_mismatch.empty:
    print("\nRevenue Mismatches Found:")
    print(revenue_mismatch[['Product', 'UnitPrice', 'QuantitySold', 'TotalRevenue', 'CalculatedRevenue']])

    # Correct the mismatches through updating the TotalRevenue
    df.loc[revenue_mismatch.index, 'TotalRevenue'] = df.loc[revenue_mismatch.index, 'UnitPrice'] * df.loc[revenue_mismatch.index, 'QuantitySold']

# Convert date to datetime
df["Date"] = pd.to_datetime(df["Date"])

# Standardize Fixing the text Fields
df["Product"] = df["Product"].str.strip().str.title()
df["Customer"] = df["Customer"].str.strip().str.title()
df["Category"] = df["Category"].str.strip().str.title()
df['Region'] = df['Region'].str.strip().str.title()

# Extract Month and weekday
df["Month"] = df["Date"].dt.month_name()
df["Weekday"] = df["Date"].dt.day_name()

# Save the cleaned Dataset
df.to_csv('output/cleaned_data.csv', index=False)
print("\nCleaned Data Saved to 'output/cleaned_data.csv'")

# EDA
print("\n======== Exploratory Data Analysis ========\n")

# Summary Statistics
print("\nSummary Statistics")
print(df.describe())

# Sales Over Time
monthly_sales = df.groupby(df["Date"].dt.to_period("M"))["TotalRevenue"].sum().reset_index()
monthly_sales = monthly_sales.rename(columns={"Date": "Month", "TotalRevenue": "MonthlySales"})
print("\nMonthly Sales")
print(monthly_sales)

# Line Plot Monthly Sales diagram
plt.figure(figsize=(12, 6))
monthly_sales['Month'] = monthly_sales['Month'].astype(str)
sns.lineplot(data=monthly_sales, x="Month", y="MonthlySales", marker='o')
plt.title("Monthly Sales Revenue(March - June 2025)", fontsize = 14)
plt.xlabel("Month", fontsize = 12)
plt.ylabel("Total Revenue ($)", fontsize = 12)
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('output/monthly_sales.png')
plt.close()
print("Monthly sales trend plot saved to output/monthly_sales.png")

# Top Products Revenue
top_products = df.groupby("Product")["TotalRevenue"].sum().sort_values(ascending=False).head(10)
plt.figure(figsize=(12,6))
sns.barplot(x=top_products.values, y=top_products.index, palette="viridis")
plt.title("Top 10 Products by Revenue", fontsize = 14)
plt.xlabel("Total Revenue ($)", fontsize = 12)
plt.ylabel("Product", fontsize = 12)
plt.tight_layout()
plt.savefig('output/top_products.png')
plt.close()
print("Top products plot saved to output/top_products.png")
print("\nTop 10 Products by Revenue")

# Product Category Total Revenue
category_sales = df.groupby("Category")["TotalRevenue"].sum().reset_index().sort_values(by='TotalRevenue', ascending=False)
print(category_sales)

# Sales by Category
category_sales = df.groupby("Category")["TotalRevenue"].sum().reset_index().sort_values(by="TotalRevenue", ascending=False)
plt.figure(figsize=(12, 6))
sns.barplot(data=category_sales, x="Category", y="TotalRevenue", palette="viridis")
plt.title("Sales by Category", fontsize = 14)
plt.xlabel("Category", fontsize = 12)
plt.ylabel("Total Revenue ($)", fontsize = 12)
plt.tight_layout()
plt.savefig('output/sales_by_category.png')
plt.close()
print("Sales by category plot saved to output/sales_by_category.png")

category_sales = df.groupby('Category')['TotalRevenue'].sum().sort_values(ascending=False)
plt.figure(figsize=(8, 6))
sns.barplot(x=category_sales.values, y=category_sales.index)
plt.title('Sales by Category', fontsize=14)
plt.xlabel('Total Revenue ($)', fontsize=12)
plt.ylabel('Category', fontsize=12)
plt.tight_layout()
plt.savefig('output/category_sales.png')
plt.close()
print("Category sales plot saved to 'output/category_sales.png'")

# Create the Top Regions revenue
top_region = df.groupby("Region")["TotalRevenue"].sum().reset_index().sort_values(by="TotalRevenue", ascending=False).head(5)
plt.figure(figsize=(12,6))
sns.barplot(x=top_region["Region"], y=top_region["TotalRevenue"], palette="viridis")
plt.title("Top 5 Regions by Total Revenue", fontsize = 14)
plt.xlabel("Region", fontsize = 12)
plt.ylabel("Total Revenue ($)", fontsize = 12)
plt.tight_layout()
plt.savefig('output/top_regions.png')
plt.close()
print("Top regions plot saved to output/top_regions.png")

# Customers order Frequency
customer_frequency = df.groupby("Customer")["QuantitySold"].count().reset_index().head(5)
customer_frequency = customer_frequency.rename(columns={"QuantitySold": "OrderFrequency"})
print("\nCustomer Order Frequency")
print(customer_frequency)

customer_frequency = df["Customer"].value_counts().head(5)
plt.figure(figsize=(12, 6))
sns.barplot(x=customer_frequency.index, y=customer_frequency.values, palette="viridis")
plt.title("Top 5 Customers by Order Frequency", fontsize = 14)
plt.xlabel("Customer", fontsize = 12)
plt.ylabel("Number of Purchases", fontsize = 12)
plt.tight_layout()
plt.savefig('output/customer_frequency.png')
plt.close()
print("Top customers order frequency plot saved to 'output/customer_frequency.png'")

# Predictive Modeling
print("\n======== Predictive Modeling ========\n")

# Prepare data for modeling
model_df = df.copy()
model_df['Month'] = model_df['Date'].dt.month
model_df['Day'] = model_df['Date'].dt.day
model_df['Weekday'] = model_df['Date'].dt.weekday

# Encode categorical variables
model_df = pd.get_dummies(model_df, columns=['Product', 'Category', 'Region'], drop_first=True)

# Split data
X = model_df.drop(['TotalRevenue', 'Date', 'Customer', 'CalculatedRevenue'], axis=1)
y = model_df['TotalRevenue']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predict and evaluate
y_pred = rf_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"\nRandom Forest Model Performance:")
print(f"Mean Squared Error: {mse:.2f}")
print(f"R-squared: {r2:.2f}")

# Feature Importance
feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False).head(10)
plt.figure(figsize=(12,6))
sns.barplot(x=feature_importances.values, y=feature_importances.index, palette="viridis")
plt.title("Top 10 Features by Importance", fontsize = 14)
plt.xlabel("Importance", fontsize = 12)
plt.ylabel("Feature", fontsize = 12)
plt.tight_layout()
plt.savefig('output/feature_importance.png')
plt.close()
print("Feature importance plot saved to output/feature_importance.png")

# Business Insights and Recommendations
print("\n======== Business Insights and Recommendations ========\n")

# Top selling Categories and products
top_products_df = df.groupby("Product")["TotalRevenue"].sum().sort_values(ascending=False).head(5)
print("\nTop 5 Selling Products")
print(top_products_df)

top_categories_df = df.groupby("Category")["TotalRevenue"].sum().sort_values(ascending=False).head(5)
print("\nTop 5 Selling Categories")
print(top_categories_df)

# High-value customers
high_value_customers = df.groupby("Customer")["TotalRevenue"].sum().sort_values(ascending=False).head(5)
print("\nTop 5 High-Value Customers")
print(high_value_customers)

# Regional performance
regional_performance = df.groupby("Region")["TotalRevenue"].sum().sort_values(ascending=False).head()
print("\nRegional Performance")
print(regional_performance)

# Recommendations
with open("output/recommendations.txt", "w") as f:
    f.write("Business Recommendations:\n")
    f.write("1. Focus inventory on top-selling products like Whiskey and Brandy, which generate the highest revenue.\n")
    f.write("2. Target high-value customers (e.g., top 5 by revenue) with personalized promotions.\n")
    f.write("3. Expand marketing efforts in top regions like Kimberlyport and South Mariaberg.\n")
    f.write("4. Consider bundling Liquor with Soft Drinks for cross-selling opportunities.\n")
print("Business recommendations saved to 'output/business_recommendations.txt'")

# Advanced Analytics
print("\n======== Advanced Analytics ========\n")
# Create a basket for each transaction
basket = df.pivot_table(index='Customer', columns='Product', values='QuantitySold', aggfunc='sum', fill_value=0)
basket = basket.applymap(lambda x: 1 if x > 0 else 0)

# Apply Apriori Algorithm
frequent_itemsets = apriori(basket, min_support=0.01, use_colnames=True)
rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1)
rules = rules.sort_values("lift", ascending=False).head(5)
print("\nTop 5 Association Rules(Market Basket Analysis):")
print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])

# Save rules
rules.to_csv('output/market_basket_rules.csv', index=False)
print("Market basket rules saved to 'output/market_basket_rules.csv'")

# Customer Segmentation
#prepare the data for clustering
print("\n======== Customer Segmentation ========\n")
cluster_df = df.groupby("Customer").agg({"TotalRevenue": "sum","QuantitySold": "sum","Product" : "nunique"}).reset_index()
cluster_df.columns = ["Customer", "TotalRevenue", "TotalQuantity", "UniqueProducts"]

# Standardize The Features
scaler = StandardScaler()
scaleds_feaurures = scaler.fit_transform(cluster_df[["TotalRevenue", "TotalQuantity", "UniqueProducts"]])

# Apply K-means
kmeans = KMeans(n_clusters=5, random_state=42)
cluster_df["Cluster"] = kmeans.fit_predict(scaleds_feaurures)

# Visualize clusters
plt.figure(figsize=(12,6))
sns.scatterplot(data=cluster_df, x="TotalRevenue", y="TotalQuantity", hue="Cluster", size="UniqueProducts", palette="viridis")
plt.title("Customer Segmentation by Revenue and Quantity", fontsize = 1)
plt.xlabel("Total Revenue ($)", fontsize = 12)
plt.ylabel("Total Quantity Sold", fontsize = 12)
plt.tight_layout()
plt.savefig('output/customer_segmentation.png')
plt.close()
print("Customer segmentation plot saved to 'output/customer_segmentation.png'")

# Save Clustered data
cluster_df.to_csv('output/clustered_data.csv', index=False)
print("Clustered data saved to 'output/clustered_data.csv'")
print("\n### Analysis Complete! All outputs saved in the 'Output' folder. ###")